{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import some necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Extract the training images and include them in different subdirectories based on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import bson\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.data import imread\n",
    "import multiprocessing as mp\n",
    "from pprint import pprint\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from itertools import islice\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def processing(s):\n",
    "    \"\"\"Read images of different products from the train.bson in batches and save \n",
    "    them as JPEG files under different folders that correspond to their categorie\"\"\"\n",
    "    data = bson.decode_file_iter(open('/home/jin/storage/train.bson', 'rb'))\n",
    "    section = islice(data, s*1000000, (s+1)*1000000)\n",
    "    for item in tqdm(section, total=1000000):\n",
    "        _id = item['_id']\n",
    "        category = item['category_id']\n",
    "        if not os.path.exists('train/%s' % category):\n",
    "            os.system('mkdir train/%s' % category)\n",
    "        pics = item['imgs'] \n",
    "        for i in range(len(pics)):\n",
    "            pic = pics[i]  \n",
    "            img = Image.open(io.BytesIO(pic['picture']))\n",
    "            img.save('train/%d/train_%d_%d.jpg' % (category, _id, i), 'JPEG')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/1000000 [00:00<1:40:43, 165.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 0th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [33:04<00:00, 503.91it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 1th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [31:39<00:00, 526.54it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 2th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:43<00:00, 509.36it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 3th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:24<00:00, 514.19it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 4th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:26<00:00, 513.75it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 5th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:28<00:00, 513.10it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 6th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:58<00:00, 505.53it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 7th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 69896/1000000 [04:06<54:37, 283.78it/s]  \n"
     ]
    }
   ],
   "source": [
    "n_batches = int(np.ceil(float(n_data)/1000000))\n",
    "for i in range(0, n_batches):\n",
    "    print(\"process %dth batch\" % i)\n",
    "    result = processing(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Pair the list of file paths and the corresponding list of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "category_folders = glob('train/*/')\n",
    "sets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5270/5270 [00:47<00:00, 111.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "categories = []\n",
    "for i in tqdm(category_folders):\n",
    "    category = i.split('/')[-2]\n",
    "    categories.append(category)\n",
    "    figs = glob(i+'*')\n",
    "    targets = [category]*len(figs)\n",
    "    pairs = [[x,y] for x, y in zip(figs, targets)]\n",
    "    sets.append(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Calculate the number of figures contained in each category and make a statistic plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3890d2c588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "n_figs_category = [len(i) for i in sets]\n",
    "n_figs_category_sorted = sorted(n_figs_category)\n",
    "n_figs  = sum(n_figs_category)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = range(1,5271)\n",
    "y1 = [1]*5270\n",
    "red_line =  [360]*5270\n",
    "ax.plot(x, n_figs_category_sorted, lw = 1)\n",
    "ax.plot(x, red_line, 'r', lw=0.5)\n",
    "ax.set_yscale('log')\n",
    "ax.fill_between(x,y1, n_figs_category_sorted, alpha=0.3)\n",
    "plt.xlabel('category')\n",
    "plt.ylabel('number of images in the category')\n",
    "plt.savefig('figures/n_instances_category.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2347.493928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8297.135538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>362.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1287.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80348.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               data\n",
       "count   5270.000000\n",
       "mean    2347.493928\n",
       "std     8297.135538\n",
       "min       12.000000\n",
       "25%      129.000000\n",
       "50%      362.000000\n",
       "75%     1287.000000\n",
       "max    80348.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some statistics about the number of images\n",
    "# contained in different categories\n",
    "df = pd.DataFrame({'data':n_figs_category})\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Split the list of image file paths into training, test and validation data sets and save them as .pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5270/5270 [00:05<00:00, 906.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "train = []\n",
    "test = []\n",
    "valid = []\n",
    "\n",
    "n_train_category = 300 # Only include maximum 300 training exampels each category\n",
    "n_test_category = 30 # The maximum number of test/vlidation samples for each category\n",
    "\n",
    "train_old=0\n",
    "test_old=0\n",
    "valid_old =0\n",
    "\n",
    "# The list of image paths for training, test, and validation set have the format:\n",
    "# [[image_path_1, category_id_1],[image_path_2, category_id_2]...] \n",
    "for i in tqdm(sets):\n",
    "    shuffle(i) # randomize the training, test and validation set\n",
    "    if len(i) < (int(n_test_category/0.15)+1):\n",
    "        seg = int(len(i)*0.15)\n",
    "        train += i[:-seg*2]\n",
    "        test += i[-seg*2: -seg]\n",
    "        valid += i[-seg:]\n",
    "    elif (int(n_test_category/0.15)+1) <= len(i) < n_test_category*2 + n_train_category:\n",
    "        train += i[:-n_test_category*2]\n",
    "        test += i[-n_test_category*2: -n_test_category]\n",
    "        valid += i[-n_test_category:]\n",
    "    else:\n",
    "        train += i[:300]\n",
    "        test += i[-n_test_category*2: -n_test_category]\n",
    "        valid += i[-n_test_category:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081356 128168 128168\n"
     ]
    }
   ],
   "source": [
    "# Number of images in the train, test and valid set\n",
    "print(len(train), len(test), len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load, dump, HIGHEST_PROTOCOL\n",
    "\n",
    "# Save the image paths for training, test and validation sets respectively\n",
    "with open('datasets/train1.pickle', 'wb') as f:\n",
    "    dump(train, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/valid1.pickle', 'wb') as f:\n",
    "    dump(valid, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/test1.pickle', 'wb') as f:\n",
    "    dump(test, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/total1.pickle', 'wb') as f:\n",
    "    dump(sets, f, HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace the ID numbers of the 5270 different categories with integral indices from 0 to 5269\n",
    "# according to their sequence in the file \"category_names.csv\"\n",
    "category = list(pd.read_csv('category_names.csv')['category_id'])\n",
    "train_i = []\n",
    "test_i = []\n",
    "valid_i = []\n",
    "for item in train:\n",
    "    x_ = item[0]\n",
    "    y_ = category.index(int(item[1]))\n",
    "    train_i.append([x_, y_])\n",
    "shuffle(train_i)\n",
    "for item in test:\n",
    "    x_ = item[0]\n",
    "    y_ = category.index(int(item[1]))\n",
    "    test_i.append([x_, y_])\n",
    "for item in valid:\n",
    "    x_ = item[0]\n",
    "    y_ = category.index(int(item[1]))\n",
    "    valid_i.append([x_, y_])\n",
    "    \n",
    "# Save the image paths for training, test and validation sets with the replaced category indices\n",
    "with open('datasets/train_i1.pickle', 'wb') as f:\n",
    "    dump(train_i, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/valid_i1.pickle', 'wb') as f:\n",
    "    dump(valid_i, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/test_i1.pickle', 'wb') as f:\n",
    "    dump(test_i, f, HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the generator to feed the training/validation/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image  \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    \"\"\"Load an image with the given path img_path in to a 224 x 224 x 3 numpy matrix\"\"\"\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    \"\"\"Load a series of N images with given paths contained in the list img_paths\n",
    "    into a N x 224 x 224 x 3 numpy matrix\"\"\"\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "def seg(x, y, batch_size):\n",
    "    \"\"\"Segment the list of training/test/validation file paths and their corresponding labels into sections according to the batch size\"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    if len(x)%batch_size:\n",
    "        steps = len(x)//batch_size+1\n",
    "    else:\n",
    "        steps = len(x)//batch_size\n",
    "    for i in range(steps):\n",
    "        if i != steps - 1:\n",
    "            section_x = x[i*batch_size:(i+1)*batch_size]          \n",
    "            section_y = y[i*batch_size:(i+1)*batch_size]               \n",
    "        else:\n",
    "            section_x = x[i*batch_size:] \n",
    "            section_y = y[i*batch_size:]\n",
    "        X.append(section_x)\n",
    "        Y.append(section_y)\n",
    "        \n",
    "    return X, Y\n",
    "            \n",
    "        \n",
    "def feed_data(X, Y):\n",
    "    \"\"\"Yield a batch of pixel matrices of images as well as their corresponding category indices\"\"\"\n",
    "    while 1:\n",
    "        for files, labels in zip(X,Y):\n",
    "            targets = []\n",
    "            for i in labels:\n",
    "                item = [0]*5270\n",
    "                item[int(i)] = 1\n",
    "                targets.append(item)\n",
    "            # Rescale the pixel values in the matrices of images into the range from -1 to 1\n",
    "            features = preprocess_input(paths_to_tensor(files))\n",
    "            yield features, np.array(targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "with open('datasets/train_i1.pickle', 'rb') as f:\n",
    "    train_set = np.array(load(f))\n",
    "with open('datasets/valid_i1.pickle', 'rb') as f:\n",
    "    valid_set = np.array(load(f))\n",
    "with open('datasets/test_i1.pickle', 'rb') as f:\n",
    "    test_set = np.array(load(f))\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "# Calculate the number of batches for the training set  \n",
    "if len(train_set)%batch_size:\n",
    "    steps_train = len(train_set)//batch_size+1\n",
    "else:\n",
    "    steps_train = len(train_set)//batch_size\n",
    "\n",
    "# Calculate the number of batches for the validation set  \n",
    "if len(valid_set)%batch_size:\n",
    "    steps_valid = len(valid_set)//batch_size+1\n",
    "else:\n",
    "    steps_valid = len(valid_set)//batch_size\n",
    "    \n",
    "# Calculate the number of batches for the test set  \n",
    "if len(test_set)%batch_size:\n",
    "    steps_valid = len(test_set)//batch_size+1\n",
    "else:\n",
    "    steps_valid = len(test_set)//batch_size\n",
    "    \n",
    "# Segment the list of training/test/validation file paths \n",
    "# and their corresponding labels into sections according to the batch size\n",
    "X_train,Y_train = seg(train_set[:,0], train_set[:,1], batch_size)\n",
    "X_valid, Y_valid = seg(valid_set[:,0], valid_set[:,1], batch_size)\n",
    "X_test, Y_test = seg(test_set[:,0], test_set[:,1], batch_size)\n",
    "\n",
    "# Prepare the generator \n",
    "train_gen = feed_data(X_train, Y_train)\n",
    "valid_gen = feed_data(X_valid, Y_valid)\n",
    "test_gen = feed_data(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benchmark model\n",
    "### 3.1 Build the model with a vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 512)     14336     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 74, 74, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 2048)      18876416  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5270)              10798230  \n",
      "=================================================================\n",
      "Total params: 34,408,598\n",
      "Trainable params: 34,408,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout,MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "model_vanilla = Sequential()\n",
    "model_vanilla.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "model_vanilla.add(MaxPooling2D(pool_size=3))\n",
    "model_vanilla.add(Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu'))\n",
    "model_vanilla.add(MaxPooling2D(pool_size=3))\n",
    "model_vanilla.add(Conv2D(filters=2048, kernel_size=3, padding='same', activation='relu'))\n",
    "model_vanilla.add(MaxPooling2D(pool_size=3))\n",
    "model_vanilla.add(GlobalAveragePooling2D())\n",
    "model_vanilla.add(Dropout(0.4))\n",
    "model_vanilla.add(Dense(5270, activation='softmax'))\n",
    "model_vanilla.load_weights(\"weights/weights.best.vanilla1.hdf5\")\n",
    "model_vanilla.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_vanilla.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "check_pointer = ModelCheckpoint(filepath=\"weights/weights.best.vanilla1.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "135169/135170 [============================>.] - ETA: 0s - loss: 16.1140 - acc: 2.5709e-04Epoch 00001: val_loss improved from inf to 16.11432, saving model to weights/weights.best.vanilla1.hdf5\n",
      "135170/135170 [==============================] - 42759s 316ms/step - loss: 16.1140 - acc: 2.5708e-04 - val_loss: 16.1143 - val_acc: 2.3407e-04\n",
      "Epoch 2/8\n",
      "135169/135170 [============================>.] - ETA: 0s - loss: 16.1140 - acc: 2.5709e-04Epoch 00002: val_loss did not improve\n",
      "135170/135170 [==============================] - 42684s 316ms/step - loss: 16.1140 - acc: 2.5708e-04 - val_loss: 16.1143 - val_acc: 2.3407e-04\n",
      "Epoch 3/8\n",
      "135169/135170 [============================>.] - ETA: 0s - loss: 16.1140 - acc: 2.5709e-04Epoch 00003: val_loss did not improve\n",
      "135170/135170 [==============================] - 42953s 318ms/step - loss: 16.1140 - acc: 2.5708e-04 - val_loss: 16.1143 - val_acc: 2.3407e-04\n",
      "Epoch 4/8\n",
      " 18778/135170 [===>..........................] - ETA: 9:55:17 - loss: 16.1151 - acc: 1.8639e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-5036dd392617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_vanilla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck_pointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1221\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2112\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2113\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2114\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_vanilla.fit_generator(train_gen, steps_per_epoch=steps_train, epochs=8, callbacks=[check_pointer], verbose=1, validation_data=valid_gen, validation_steps=steps_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test the model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = test_set[:,0], test_set[:,1]\n",
    "labels= labels.astype('int')\n",
    "\n",
    "def predict(paths, batch_size=256):\n",
    "    n_batches = int(np.ceil(len(paths)/batch_size))\n",
    "    predictions = []\n",
    "    for n in tqdm(range(n_batches)):\n",
    "        if n != n_batches-1:\n",
    "            paths_n = paths[n*batch_size:(n+1)*batch_size]\n",
    "        else:\n",
    "            paths_n = paths[n*batch_size:]\n",
    "        X = paths_to_tensor(paths_n)\n",
    "        predictions += list(np.argmax(model_vanilla.predict(preprocess_input(X)), axis=1))\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [21:11<00:00,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.000234067786031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions =predict(features, batch_size=1000)\n",
    "print('accuracy: ', sum(predictions == labels)/len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. My solution (stage I) - only train the last fully connected layer of pre-trained ResNet50 model\n",
    "### 4.1 Use transfer learning technique to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 55, 55, 256)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 55, 55, 256)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 55, 55, 256)  0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 28, 28, 512)  0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 28, 28, 512)  0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 28, 28, 512)  0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 28, 28, 512)  0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 14, 14, 1024) 0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 14, 14, 1024) 0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 14, 14, 1024) 0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 14, 14, 1024) 0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 14, 14, 1024) 0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 14, 14, 1024) 0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 2048)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 7, 7, 2048)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 7, 7, 2048)   0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5270)         10798230    flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 34,385,942\n",
      "Trainable params: 10,798,230\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout,GlobalAveragePooling2D\n",
    "\n",
    "# Remove the last FC layer of ResNet50 with pretrained weights and add a new FC layer\n",
    "base_model = ResNet50(weights='imagenet')\n",
    "\n",
    "x = base_model.layers[-2].output\n",
    "output = Dense(5270, activation='softmax')(x)\n",
    "model = Model(input=base_model.input, output=output)\n",
    "\n",
    "# Only train the weights of the new FC layer\n",
    "for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "check_pointer = ModelCheckpoint(filepath='weights/weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch=steps_train, epochs=8, verbose=1,\n",
    "                             callbacks=[check_pointer], validation_data=valid_gen, validation_steps=steps_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test the model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = test_set[:,0], test_set[:,1]\n",
    "labels= labels.astype('int')\n",
    "\n",
    "def predict(paths, batch_size=256):\n",
    "    n_batches = int(np.ceil(len(paths)/batch_size))\n",
    "    predictions = []\n",
    "    for n in tqdm(range(n_batches)):\n",
    "        if n != n_batches-1:\n",
    "            paths_n = paths[n*batch_size:(n+1)*batch_size]\n",
    "        else:\n",
    "            paths_n = paths[n*batch_size:]\n",
    "        X = paths_to_tensor(paths_n)\n",
    "        predictions += list(np.argmax(model.predict(preprocess_input(X)), axis=1))\n",
    "    return np.array(predictions)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [14:01<00:00,  6.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.36445134511\n"
     ]
    }
   ],
   "source": [
    "predictions =predict(features, batch_size=1000)\n",
    "print('accuracy: ', sum(predictions == labels)/len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 My solution (stage I) - fine tunning of the previous model\n",
    "### 5.1 Fine tune the weights of the entire ResNet50 model based on the previous training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1a  Fine tune the learning rate of the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout,GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_model(lr=0.01):\n",
    "    base_model = ResNet50(weights='imagenet') \n",
    "    x = base_model.layers[-2].output\n",
    "    prediction = Dense(5270, activation='softmax')(x)\n",
    "    model_fine = Model(input=base_model.input, output=prediction)\n",
    "    model_fine.load_weights(\"weights/weights.best7.hdf5\")\n",
    "    optimizer = Adam(lr=lr)\n",
    "    model_fine.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model_fine\n",
    "\n",
    "param_grid = dict(lr=[0.00001, 0.000033, 0.0001, 0.00033, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2162/2162 [01:33<00:00, 23.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# The hyper-parameter tunning will be performed on the first 1/20 of the training set\n",
    "X = []\n",
    "Y = []\n",
    "steps_tune = int(steps_train/20)\n",
    "for i in tqdm(range(steps_tune)):\n",
    "    x, y = next(train_gen)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "X = np.vstack(X)\n",
    "Y = np.concatenate(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=4, batch_size=15, verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "36033/36033 [==============================] - 706s 20ms/step - loss: 2.6189 - acc: 0.4645\n",
      "Epoch 2/4\n",
      "36033/36033 [==============================] - 573s 16ms/step - loss: 1.5990 - acc: 0.6424\n",
      "Epoch 3/4\n",
      "36033/36033 [==============================] - 571s 16ms/step - loss: 1.0124 - acc: 0.7739\n",
      "Epoch 4/4\n",
      "36033/36033 [==============================] - 571s 16ms/step - loss: 0.6431 - acc: 0.8626\n",
      "18017/18017 [==============================] - 179s 10ms/step\n",
      "36033/36033 [==============================] - 251s 7ms/step\n",
      "Epoch 1/4\n",
      "36033/36033 [==============================] - 666s 18ms/step - loss: 2.5549 - acc: 0.4709\n",
      "Epoch 2/4\n",
      "36033/36033 [==============================] - 544s 15ms/step - loss: 1.5556 - acc: 0.6541\n",
      "Epoch 3/4\n",
      "36033/36033 [==============================] - 543s 15ms/step - loss: 1.0004 - acc: 0.7732\n",
      "Epoch 4/4\n",
      "36033/36033 [==============================] - 543s 15ms/step - loss: 0.6312 - acc: 0.8617\n",
      "18017/18017 [==============================] - 180s 10ms/step\n",
      "36033/36033 [==============================] - 242s 7ms/step\n",
      "Epoch 1/4\n",
      "36034/36034 [==============================] - 669s 19ms/step - loss: 2.5425 - acc: 0.4707\n",
      "Epoch 2/4\n",
      "36034/36034 [==============================] - 545s 15ms/step - loss: 1.5340 - acc: 0.6527\n",
      "Epoch 3/4\n",
      "36034/36034 [==============================] - 544s 15ms/step - loss: 0.9754 - acc: 0.7752\n",
      "Epoch 4/4\n",
      "36034/36034 [==============================] - 544s 15ms/step - loss: 0.6205 - acc: 0.8642\n",
      "18016/18016 [==============================] - 190s 11ms/step\n",
      "36034/36034 [==============================] - 244s 7ms/step\n",
      "Epoch 1/4\n",
      "36033/36033 [==============================] - 671s 19ms/step - loss: 2.9324 - acc: 0.4144\n",
      "Epoch 2/4\n",
      "36033/36033 [==============================] - 545s 15ms/step - loss: 1.3276 - acc: 0.7019\n",
      "Epoch 3/4\n",
      "36033/36033 [==============================] - 545s 15ms/step - loss: 0.6128 - acc: 0.8676\n",
      "Epoch 4/4\n",
      "36033/36033 [==============================] - 545s 15ms/step - loss: 0.3820 - acc: 0.9242\n",
      "18017/18017 [==============================] - 196s 11ms/step\n",
      "36033/36033 [==============================] - 254s 7ms/step\n",
      "Epoch 1/4\n",
      "36033/36033 [==============================] - 672s 19ms/step - loss: 2.9150 - acc: 0.4153\n",
      "Epoch 2/4\n",
      "36033/36033 [==============================] - 546s 15ms/step - loss: 1.3073 - acc: 0.7058\n",
      "Epoch 3/4\n",
      "36033/36033 [==============================] - 546s 15ms/step - loss: 0.6078 - acc: 0.8637\n",
      "Epoch 4/4\n",
      "36033/36033 [==============================] - 546s 15ms/step - loss: 0.3786 - acc: 0.9242\n",
      "18017/18017 [==============================] - 204s 11ms/step\n",
      "36033/36033 [==============================] - 249s 7ms/step\n",
      "Epoch 1/4\n",
      "36034/36034 [==============================] - 673s 19ms/step - loss: 2.8901 - acc: 0.4173\n",
      "Epoch 2/4\n",
      "36034/36034 [==============================] - 546s 15ms/step - loss: 1.2840 - acc: 0.7094\n",
      "Epoch 3/4\n",
      "36034/36034 [==============================] - 546s 15ms/step - loss: 0.5937 - acc: 0.8700\n",
      "Epoch 4/4\n",
      "36034/36034 [==============================] - 546s 15ms/step - loss: 0.3699 - acc: 0.9241\n",
      "18016/18016 [==============================] - 213s 12ms/step\n",
      "36034/36034 [==============================] - 251s 7ms/step\n",
      "Epoch 1/4\n",
      "36033/36033 [==============================] - 673s 19ms/step - loss: 4.1460 - acc: 0.2654\n",
      "Epoch 2/4\n",
      "36033/36033 [==============================] - 547s 15ms/step - loss: 2.1670 - acc: 0.5413\n",
      "Epoch 3/4\n",
      "36033/36033 [==============================] - 547s 15ms/step - loss: 1.0591 - acc: 0.7603\n",
      "Epoch 4/4\n",
      "36033/36033 [==============================] - 547s 15ms/step - loss: 0.6392 - acc: 0.8541\n",
      "18017/18017 [==============================] - 219s 12ms/step\n",
      "36033/36033 [==============================] - 252s 7ms/step\n",
      "Epoch 1/4\n",
      "36033/36033 [==============================] - 675s 19ms/step - loss: 4.1284 - acc: 0.2631\n",
      "Epoch 2/4\n",
      "36033/36033 [==============================] - 548s 15ms/step - loss: 2.1804 - acc: 0.5387\n",
      "Epoch 3/4\n",
      "36033/36033 [==============================] - 548s 15ms/step - loss: 1.0456 - acc: 0.7603\n",
      "Epoch 4/4\n",
      "36033/36033 [==============================] - 548s 15ms/step - loss: 0.6616 - acc: 0.8496\n",
      "18017/18017 [==============================] - 227s 13ms/step\n",
      "36033/36033 [==============================] - 254s 7ms/step\n",
      "Epoch 1/4\n",
      "36034/36034 [==============================] - 677s 19ms/step - loss: 4.1038 - acc: 0.2636\n",
      "Epoch 2/4\n",
      "36034/36034 [==============================] - 549s 15ms/step - loss: 2.1273 - acc: 0.5467\n",
      "Epoch 3/4\n",
      "36034/36034 [==============================] - 549s 15ms/step - loss: 1.0236 - acc: 0.7646\n",
      "Epoch 4/4\n",
      "36034/36034 [==============================] - 549s 15ms/step - loss: 0.6206 - acc: 0.8569\n",
      "18016/18016 [==============================] - 236s 13ms/step\n",
      "36034/36034 [==============================] - 255s 7ms/step\n",
      "Epoch 1/4\n",
      "36033/36033 [==============================] - 678s 19ms/step - loss: 6.3912 - acc: 0.0876\n",
      "Epoch 2/4\n",
      "36033/36033 [==============================] - 550s 15ms/step - loss: 4.1433 - acc: 0.2593\n",
      "Epoch 3/4\n",
      "36033/36033 [==============================] - 550s 15ms/step - loss: 2.4274 - acc: 0.4907\n",
      "Epoch 4/4\n",
      "36033/36033 [==============================] - 550s 15ms/step - loss: 1.2341 - acc: 0.7187\n",
      "18017/18017 [==============================] - 238s 13ms/step\n",
      "36033/36033 [==============================] - 259s 7ms/step\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[15,7,7,512]\n\t [[Node: res5c_branch2a_10/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_536/Relu, res5c_branch2a_10/kernel/read)]]\n\t [[Node: metrics_10/acc/Mean/_54915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_25015_metrics_10/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'res5c_branch2a_10/convolution', defined at:\n  File \"/home/jin/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/jin/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-61170a4ec618>\", line 1, in <module>\n    grid_result = grid.fit(X,Y)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n    cv.split(X, y, groups)))\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 203, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 136, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n  File \"<ipython-input-5-7dacd94787a6>\", line 9, in create_model\n    base_model = ResNet50(weights='imagenet')\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/applications/resnet50.py\", line 230, in ResNet50\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/applications/resnet50.py\", line 61, in identity_block\n    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3189, in conv2d\n    data_format=tf_data_format)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[15,7,7,512]\n\t [[Node: res5c_branch2a_10/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_536/Relu, res5c_branch2a_10/kernel/read)]]\n\t [[Node: metrics_10/acc/Mean/_54915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_25015_metrics_10/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[15,7,7,512]\n\t [[Node: res5c_branch2a_10/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_536/Relu, res5c_branch2a_10/kernel/read)]]\n\t [[Node: metrics_10/acc/Mean/_54915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_25015_metrics_10/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-61170a4ec618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[15,7,7,512]\n\t [[Node: res5c_branch2a_10/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_536/Relu, res5c_branch2a_10/kernel/read)]]\n\t [[Node: metrics_10/acc/Mean/_54915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_25015_metrics_10/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'res5c_branch2a_10/convolution', defined at:\n  File \"/home/jin/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/jin/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-61170a4ec618>\", line 1, in <module>\n    grid_result = grid.fit(X,Y)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n    cv.split(X, y, groups)))\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n    while self.dispatch_one_batch(iterator):\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n    result = ImmediateResult(func)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n    self.results = batch()\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 203, in fit\n    return super(KerasClassifier, self).fit(x, y, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\", line 136, in fit\n    self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n  File \"<ipython-input-5-7dacd94787a6>\", line 9, in create_model\n    base_model = ResNet50(weights='imagenet')\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/applications/resnet50.py\", line 230, in ResNet50\n    x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/applications/resnet50.py\", line 61, in identity_block\n    x = Conv2D(filters1, (1, 1), name=conv_name_base + '2a')(input_tensor)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 603, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 3189, in conv2d\n    data_format=tf_data_format)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 751, in convolution\n    return op(input, filter)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\n    return self.conv_op(inp, filter)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\n    return self.call(inp, filter)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\n    name=self.name)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\n    data_format=data_format, name=name)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/jin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[15,7,7,512]\n\t [[Node: res5c_branch2a_10/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](activation_536/Relu, res5c_branch2a_10/kernel/read)]]\n\t [[Node: metrics_10/acc/Mean/_54915 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_25015_metrics_10/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1b  Use the optimal learning rate to fine tune the weights of the entire ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 55, 55, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5270)         10798230    flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 34,385,942\n",
      "Trainable params: 34,332,822\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout,GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights='imagenet') \n",
    "\n",
    "x = base_model.layers[-2].output\n",
    "prediction = Dense(5270, activation='softmax')(x)\n",
    "model_fine = Model(input=base_model.input, output=prediction)\n",
    "\n",
    "# Load the weights of the model trained in the previous step\n",
    "model_fine.load_weights(\"weights/weights.best7.hdf5\")\n",
    "model_fine.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Train with a much lower learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_fine.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "check_pointer = ModelCheckpoint(filepath='weights/weights.best.fine1.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 4.2222 - acc: 0.2686Epoch 00001: val_loss improved from inf to 3.93237, saving model to weights/weights.best.fine1.hdf5\n",
      "27034/27034 [==============================] - 14901s 551ms/step - loss: 4.2222 - acc: 0.2686 - val_loss: 3.9324 - val_acc: 0.3546\n",
      "Epoch 2/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 3.3939 - acc: 0.3758Epoch 00002: val_loss improved from 3.93237 to 3.72420, saving model to weights/weights.best.fine1.hdf5\n",
      "27034/27034 [==============================] - 14887s 551ms/step - loss: 3.3939 - acc: 0.3758 - val_loss: 3.7242 - val_acc: 0.3855\n",
      "Epoch 3/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 2.9462 - acc: 0.4381Epoch 00003: val_loss improved from 3.72420 to 3.58259, saving model to weights/weights.best.fine1.hdf5\n",
      "27034/27034 [==============================] - 14991s 555ms/step - loss: 2.9461 - acc: 0.4381 - val_loss: 3.5826 - val_acc: 0.4066\n",
      "Epoch 4/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 2.6229 - acc: 0.4849Epoch 00004: val_loss improved from 3.58259 to 3.57294, saving model to weights/weights.best.fine1.hdf5\n",
      "27034/27034 [==============================] - 15035s 556ms/step - loss: 2.6228 - acc: 0.4849 - val_loss: 3.5729 - val_acc: 0.4106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a40029278>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fine.fit_generator(train_gen, steps_per_epoch=steps_train, epochs=4, verbose=1,\n",
    "                             callbacks=[check_pointer], validation_data=valid_gen, validation_steps=steps_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fine.save('weights/fullmodel.best.fine1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 2.3608 - acc: 0.5234Epoch 00001: val_loss improved from inf to 3.47892, saving model to weights/weights.best.fine2.hdf5\n",
      "27034/27034 [==============================] - 15044s 556ms/step - loss: 2.3608 - acc: 0.5234 - val_loss: 3.4789 - val_acc: 0.4279\n",
      "Epoch 2/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 2.1388 - acc: 0.5569Epoch 00002: val_loss did not improve\n",
      "27034/27034 [==============================] - 15053s 557ms/step - loss: 2.1388 - acc: 0.5569 - val_loss: 3.4796 - val_acc: 0.4341\n",
      "Epoch 3/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 1.9498 - acc: 0.5871Epoch 00003: val_loss did not improve\n",
      "27034/27034 [==============================] - 15094s 558ms/step - loss: 1.9498 - acc: 0.5871 - val_loss: 3.5375 - val_acc: 0.4352\n",
      "Epoch 4/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 1.7861 - acc: 0.6122Epoch 00004: val_loss did not improve\n",
      "27034/27034 [==============================] - 15109s 559ms/step - loss: 1.7861 - acc: 0.6122 - val_loss: 3.4805 - val_acc: 0.4440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a43edbd30>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_pointer = ModelCheckpoint(filepath='weights/weights.best.fine2.hdf5', verbose=1, save_best_only=True)\n",
    "model_fine.fit_generator(train_gen, steps_per_epoch=steps_train, epochs=4, verbose=1,\n",
    "                             callbacks=[check_pointer], validation_data=valid_gen, validation_steps=steps_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Test the performance of the fine-tuned model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model_fine = load_model('weights/fullmodel.best.fine3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = test_set[:,0], test_set[:,1]\n",
    "labels= labels.astype('int')\n",
    "\n",
    "def predict(paths, batch_size=256):\n",
    "    n_batches = int(np.ceil(len(paths)/batch_size))\n",
    "    predictions = []\n",
    "    for n in tqdm(range(n_batches)):\n",
    "        if n != n_batches-1:\n",
    "            paths_n = paths[n*batch_size:(n+1)*batch_size]\n",
    "        else:\n",
    "            paths_n = paths[n*batch_size:]\n",
    "        X = paths_to_tensor(paths_n)\n",
    "        predictions += list(np.argmax(model_fine.predict(preprocess_input(X)), axis=1))\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [14:02<00:00,  6.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.449371137882\n"
     ]
    }
   ],
   "source": [
    "predictions =predict(features, batch_size=1000)\n",
    "print('accuracy: ', sum(predictions == labels)/len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fine.save('weights/fullmodel.best.fine3.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate the bottleneck features using the fine tuned model of the last step\n",
    "### 6.1 Set up the model (model_bnf) to output the predicted category and the bottleneck features before the last fully-connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, Model\n",
    "\n",
    "model = load_model('weights/fullmodel.best.fine3.hdf5')\n",
    "output = [model.layers[-2].output, model.output]\n",
    "model_bnf = Model(input=model.input, output=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Calculate the bottleneck features for all the images of the training set and save them in a sorted state according to their categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1082/1082 [2:09:04<00:00,  7.16s/it] \n"
     ]
    }
   ],
   "source": [
    "# The bottleneck features are put into a dictionary, where the keys are the indices of categories,\n",
    "# and the corresponding values are lists of bottleneck features from images with the same label.\n",
    "train_sorted = {}  \n",
    "predictions = [] # record the prediction of the model for each training image\n",
    "for n in tqdm(range(steps_train)):\n",
    "    features, labels = next(train_gen)\n",
    "    bnfeatures = model_bnf.predict(features)\n",
    "    labels_n = [list(i).index(1) for i in labels]\n",
    "    predictions += labels_n\n",
    "    for bnf, label in zip(bnfeatures, labels_n):\n",
    "        keys = train_sorted.keys()\n",
    "        if label not in keys:\n",
    "            train_sorted[label] = []\n",
    "        train_sorted[label].append(bnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load, dump, HIGHEST_PROTOCOL\n",
    "\n",
    "# Save the calculated bottleneck features and the predicted categories for the training set\n",
    "with open('bnfeature/train_fine3.pickle', 'wb') as f:\n",
    "    dump(train_sorted, f, HIGHEST_PROTOCOL)\n",
    "with open('prediction/fine3_train.pickle', 'wb') as f:\n",
    "    dump(predictions, f, HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Calculate the bottleneck features for all the images of the valid set and save them in a sorted state according to their categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_sorted = {}  \n",
    "predictions = [] \n",
    "for n in tqdm(range(steps_valid)):\n",
    "    features, labels = next(valid_gen)\n",
    "    bnfeatures = model_bnf.predict(features)\n",
    "    labels_n = [list(i).index(1) for i in labels]\n",
    "    predictions += labels_n\n",
    "    for bnf, label in zip(bnfeatures, labels_n):\n",
    "        keys = valid_sorted.keys()\n",
    "        if label not in keys:\n",
    "            valid_sorted[label] = []\n",
    "        valid_sorted[label].append(bnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load, dump, HIGHEST_PROTOCOL\n",
    "with open('bnfeature/valid3_fine.pickle', 'wb') as f:\n",
    "    dump(valid_sorted, f, HIGHEST_PROTOCOL)\n",
    "with open('prediction/fine3_valid.pickle', 'wb') as f:\n",
    "    dump(predictions, f, HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
