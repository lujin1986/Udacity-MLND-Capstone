{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import some necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Extract the training images and include them in different subdirectories based on labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import bson\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.data import imread\n",
    "import multiprocessing as mp\n",
    "from pprint import pprint\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "from itertools import islice\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def processing(s):\n",
    "    \"\"\"Read images of different products from the train.bson in batches and save \n",
    "    them as JPEG files under different folders that correspond to their categorie\"\"\"\n",
    "    data = bson.decode_file_iter(open('/home/jin/storage/train.bson', 'rb'))\n",
    "    section = islice(data, s*1000000, (s+1)*1000000)\n",
    "    for item in tqdm(section, total=1000000):\n",
    "        _id = item['_id']\n",
    "        category = item['category_id']\n",
    "        if not os.path.exists('train/%s' % category):\n",
    "            os.system('mkdir train/%s' % category)\n",
    "        pics = item['imgs'] \n",
    "        for i in range(len(pics)):\n",
    "            pic = pics[i]  \n",
    "            img = Image.open(io.BytesIO(pic['picture']))\n",
    "            img.save('train/%d/train_%d_%d.jpg' % (category, _id, i), 'JPEG')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/1000000 [00:00<1:40:43, 165.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 0th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [33:04<00:00, 503.91it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 1th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [31:39<00:00, 526.54it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 2th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:43<00:00, 509.36it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 3th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:24<00:00, 514.19it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 4th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:26<00:00, 513.75it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 5th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:28<00:00, 513.10it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 6th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [32:58<00:00, 505.53it/s]\n",
      "  0%|          | 0/1000000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 7th batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 69896/1000000 [04:06<54:37, 283.78it/s]  \n"
     ]
    }
   ],
   "source": [
    "n_batches = int(np.ceil(float(n_data)/1000000))\n",
    "for i in range(0, n_batches):\n",
    "    print(\"process %dth batch\" % i)\n",
    "    result = processing(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Pair the list of file paths and the corresponding list of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "category_folders = glob('train/*/')\n",
    "sets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5270/5270 [00:47<00:00, 111.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "categories = []\n",
    "for i in tqdm(category_folders):\n",
    "    category = i.split('/')[-2]\n",
    "    categories.append(category)\n",
    "    figs = glob(i+'*')\n",
    "    targets = [category]*len(figs)\n",
    "    pairs = [[x,y] for x, y in zip(figs, targets)]\n",
    "    sets.append(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Calculate the number of figures contained in each category and make a statistic plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3890d2c588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "n_figs_category = [len(i) for i in sets]\n",
    "n_figs_category_sorted = sorted(n_figs_category)\n",
    "n_figs  = sum(n_figs_category)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = range(1,5271)\n",
    "y1 = [1]*5270\n",
    "red_line =  [360]*5270\n",
    "ax.plot(x, n_figs_category_sorted, lw = 1)\n",
    "ax.plot(x, red_line, 'r', lw=0.5)\n",
    "ax.set_yscale('log')\n",
    "ax.fill_between(x,y1, n_figs_category_sorted, alpha=0.3)\n",
    "plt.xlabel('category')\n",
    "plt.ylabel('number of images in the category')\n",
    "plt.savefig('figures/n_instances_category.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2347.493928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8297.135538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>362.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1287.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80348.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               data\n",
       "count   5270.000000\n",
       "mean    2347.493928\n",
       "std     8297.135538\n",
       "min       12.000000\n",
       "25%      129.000000\n",
       "50%      362.000000\n",
       "75%     1287.000000\n",
       "max    80348.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get some statistics about the number of images\n",
    "# contained in different categories\n",
    "df = pd.DataFrame({'data':n_figs_category})\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Split the list of image file paths into training, test and validation data sets and save them as .pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5270/5270 [00:05<00:00, 906.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "train = []\n",
    "test = []\n",
    "valid = []\n",
    "\n",
    "n_train_category = 300 # Only include maximum 300 training exampels each category\n",
    "n_test_category = 30 # The maximum number of test/vlidation samples for each category\n",
    "\n",
    "train_old=0\n",
    "test_old=0\n",
    "valid_old =0\n",
    "\n",
    "# The list of image paths for training, test, and validation set have the format:\n",
    "# [[image_path_1, category_id_1],[image_path_2, category_id_2]...] \n",
    "for i in tqdm(sets):\n",
    "    shuffle(i) # randomize the training, test and validation set\n",
    "    if len(i) < (int(n_test_category/0.15)+1):\n",
    "        seg = int(len(i)*0.15)\n",
    "        train += i[:-seg*2]\n",
    "        test += i[-seg*2: -seg]\n",
    "        valid += i[-seg:]\n",
    "    elif (int(n_test_category/0.15)+1) <= len(i) < n_test_category*2 + n_train_category:\n",
    "        train += i[:-n_test_category*2]\n",
    "        test += i[-n_test_category*2: -n_test_category]\n",
    "        valid += i[-n_test_category:]\n",
    "    else:\n",
    "        train += i[:300]\n",
    "        test += i[-n_test_category*2: -n_test_category]\n",
    "        valid += i[-n_test_category:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081356 128168 128168\n"
     ]
    }
   ],
   "source": [
    "# Number of images in the train, test and valid set\n",
    "print(len(train), len(test), len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load, dump, HIGHEST_PROTOCOL\n",
    "\n",
    "# Save the image paths for training, test and validation sets respectively\n",
    "with open('datasets/train1.pickle', 'wb') as f:\n",
    "    dump(train, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/valid1.pickle', 'wb') as f:\n",
    "    dump(valid, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/test1.pickle', 'wb') as f:\n",
    "    dump(test, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/total1.pickle', 'wb') as f:\n",
    "    dump(sets, f, HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace the ID numbers of the 5270 different categories with integral indices from 0 to 5269\n",
    "# according to their sequence in the file \"category_names.csv\"\n",
    "category = list(pd.read_csv('category_names.csv')['category_id'])\n",
    "train_i = []\n",
    "test_i = []\n",
    "valid_i = []\n",
    "for item in train:\n",
    "    x_ = item[0]\n",
    "    y_ = category.index(int(item[1]))\n",
    "    train_i.append([x_, y_])\n",
    "shuffle(train_i)\n",
    "for item in test:\n",
    "    x_ = item[0]\n",
    "    y_ = category.index(int(item[1]))\n",
    "    test_i.append([x_, y_])\n",
    "for item in valid:\n",
    "    x_ = item[0]\n",
    "    y_ = category.index(int(item[1]))\n",
    "    valid_i.append([x_, y_])\n",
    "    \n",
    "# Save the image paths for training, test and validation sets with the replaced category indices\n",
    "with open('datasets/train_i1.pickle', 'wb') as f:\n",
    "    dump(train_i, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/valid_i1.pickle', 'wb') as f:\n",
    "    dump(valid_i, f, HIGHEST_PROTOCOL)\n",
    "with open('datasets/test_i1.pickle', 'wb') as f:\n",
    "    dump(test_i, f, HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the generator to feed the training/validation/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image  \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    \"\"\"Load an image with the given path img_path in to a 224 x 224 x 3 numpy matrix\"\"\"\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    \"\"\"Load a series of N images with given paths contained in the list img_paths\n",
    "    into a N x 224 x 224 x 3 numpy matrix\"\"\"\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "def seg(x, y, batch_size):\n",
    "    \"\"\"Segment the list of training/test/validation file paths and their corresponding labels into sections according to the batch size\"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    if len(x)%batch_size:\n",
    "        steps = len(x)//batch_size+1\n",
    "    else:\n",
    "        steps = len(x)//batch_size\n",
    "    for i in range(steps):\n",
    "        if i != steps - 1:\n",
    "            section_x = x[i*batch_size:(i+1)*batch_size]          \n",
    "            section_y = y[i*batch_size:(i+1)*batch_size]               \n",
    "        else:\n",
    "            section_x = x[i*batch_size:] \n",
    "            section_y = y[i*batch_size:]\n",
    "        X.append(section_x)\n",
    "        Y.append(section_y)\n",
    "        \n",
    "    return X, Y\n",
    "            \n",
    "        \n",
    "def feed_data(X, Y):\n",
    "    \"\"\"Yield a batch of pixel matrices of images as well as their corresponding category indices\"\"\"\n",
    "    while 1:\n",
    "        for files, labels in zip(X,Y):\n",
    "            targets = []\n",
    "            for i in labels:\n",
    "                item = [0]*5270\n",
    "                item[int(i)] = 1\n",
    "                targets.append(item)\n",
    "            # Rescale the pixel values in the matrices of images into the range from -1 to 1\n",
    "            features = preprocess_input(paths_to_tensor(files))\n",
    "            yield features, np.array(targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "with open('datasets/train_i1.pickle', 'rb') as f:\n",
    "    train_set = np.array(load(f))\n",
    "with open('datasets/valid_i1.pickle', 'rb') as f:\n",
    "    valid_set = np.array(load(f))\n",
    "with open('datasets/test_i1.pickle', 'rb') as f:\n",
    "    test_set = np.array(load(f))\n",
    "\n",
    "batch_size = 25\n",
    "\n",
    "# Calculate the number of batches for the training set  \n",
    "if len(train_set)%batch_size:\n",
    "    steps_train = len(train_set)//batch_size+1\n",
    "else:\n",
    "    steps_train = len(train_set)//batch_size\n",
    "\n",
    "# Calculate the number of batches for the validation set  \n",
    "if len(valid_set)%batch_size:\n",
    "    steps_valid = len(valid_set)//batch_size+1\n",
    "else:\n",
    "    steps_valid = len(valid_set)//batch_size\n",
    "    \n",
    "# Calculate the number of batches for the test set  \n",
    "if len(test_set)%batch_size:\n",
    "    steps_valid = len(test_set)//batch_size+1\n",
    "else:\n",
    "    steps_valid = len(test_set)//batch_size\n",
    "    \n",
    "# Segment the list of training/test/validation file paths \n",
    "# and their corresponding labels into sections according to the batch size\n",
    "X_train,Y_train = seg(train_set[:,0], train_set[:,1], batch_size)\n",
    "X_valid, Y_valid = seg(valid_set[:,0], valid_set[:,1], batch_size)\n",
    "X_test, Y_test = seg(test_set[:,0], test_set[:,1], batch_size)\n",
    "\n",
    "# Prepare the generator \n",
    "train_gen = feed_data(X_train, Y_train)\n",
    "valid_gen = feed_data(X_valid, Y_valid)\n",
    "test_gen = feed_data(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benchmark model\n",
    "### 3.1 Build the model with a vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 512)     14336     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 74, 74, 1024)      4719616   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 1024)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 2048)      18876416  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 2048)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5270)              10798230  \n",
      "=================================================================\n",
      "Total params: 34,408,598\n",
      "Trainable params: 34,408,598\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout,MaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "model_vanilla = Sequential()\n",
    "model_vanilla.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "model_vanilla.add(MaxPooling2D(pool_size=3))\n",
    "model_vanilla.add(Conv2D(filters=1024, kernel_size=3, padding='same', activation='relu'))\n",
    "model_vanilla.add(MaxPooling2D(pool_size=3))\n",
    "model_vanilla.add(Conv2D(filters=2048, kernel_size=3, padding='same', activation='relu'))\n",
    "model_vanilla.add(MaxPooling2D(pool_size=3))\n",
    "model_vanilla.add(GlobalAveragePooling2D())\n",
    "model_vanilla.add(Dropout(0.4))\n",
    "model_vanilla.add(Dense(5270, activation='softmax'))\n",
    "model_vanilla.load_weights(\"weights/weights.best.vanilla1.hdf5\")\n",
    "model_vanilla.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_vanilla.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "check_pointer = ModelCheckpoint(filepath=\"weights/weights.best.vanilla1.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla.fit_generator(train_gen, steps_per_epoch=steps_train, epochs=8, callbacks=[check_pointer], verbose=1, validation_data=valid_gen, validation_steps=steps_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test the model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = test_set[:,0], test_set[:,1]\n",
    "labels= labels.astype('int')\n",
    "\n",
    "def predict(paths, batch_size=256):\n",
    "    n_batches = int(np.ceil(len(paths)/batch_size))\n",
    "    predictions = []\n",
    "    for n in tqdm(range(n_batches)):\n",
    "        if n != n_batches-1:\n",
    "            paths_n = paths[n*batch_size:(n+1)*batch_size]\n",
    "        else:\n",
    "            paths_n = paths[n*batch_size:]\n",
    "        X = paths_to_tensor(paths_n)\n",
    "        predictions += list(np.argmax(model_vanilla.predict(preprocess_input(X)), axis=1))\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [21:11<00:00,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.000234067786031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictions =predict(features, batch_size=1000)\n",
    "print('accuracy: ', sum(predictions == labels)/len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. My solution (stage I) - only train the last fully connected layer of pre-trained ResNet50 model\n",
    "### 4.1 Use transfer learning technique to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 55, 55, 256)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 55, 55, 256)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 55, 55, 256)  0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 28, 28, 512)  0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 28, 28, 512)  0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 28, 28, 512)  0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 28, 28, 512)  0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 14, 14, 1024) 0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 14, 14, 1024) 0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 14, 14, 1024) 0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 14, 14, 1024) 0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 14, 14, 1024) 0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 14, 14, 1024) 0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 2048)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 7, 7, 2048)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 7, 7, 2048)   0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5270)         10798230    flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 34,385,942\n",
      "Trainable params: 10,798,230\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout,GlobalAveragePooling2D\n",
    "\n",
    "# Remove the last FC layer of ResNet50 with pretrained weights and add a new FC layer\n",
    "base_model = ResNet50(weights='imagenet')\n",
    "\n",
    "x = base_model.layers[-2].output\n",
    "output = Dense(5270, activation='softmax')(x)\n",
    "model = Model(input=base_model.input, output=output)\n",
    "\n",
    "# Only train the weights of the new FC layer\n",
    "for layer in base_model.layers:\n",
    "        layer.trainable=False\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "check_pointer = ModelCheckpoint(filepath='weights/weights.best.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit_generator(train_gen, steps_per_epoch=steps_train, epochs=8, verbose=1,\n",
    "                             callbacks=[check_pointer], validation_data=valid_gen, validation_steps=steps_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Test the model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = test_set[:,0], test_set[:,1]\n",
    "labels= labels.astype('int')\n",
    "\n",
    "def predict(paths, batch_size=256):\n",
    "    n_batches = int(np.ceil(len(paths)/batch_size))\n",
    "    predictions = []\n",
    "    for n in tqdm(range(n_batches)):\n",
    "        if n != n_batches-1:\n",
    "            paths_n = paths[n*batch_size:(n+1)*batch_size]\n",
    "        else:\n",
    "            paths_n = paths[n*batch_size:]\n",
    "        X = paths_to_tensor(paths_n)\n",
    "        predictions += list(np.argmax(model.predict(preprocess_input(X)), axis=1))\n",
    "    return np.array(predictions)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [14:01<00:00,  6.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.36445134511\n"
     ]
    }
   ],
   "source": [
    "predictions =predict(features, batch_size=1000)\n",
    "print('accuracy: ', sum(predictions == labels)/len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 My solution (stage I) - fine tunning of the previous model\n",
    "### 5.1 Fine tune the weights of the entire ResNet50 model based on the previous training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1a  Fine tune the learning rate of the Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout,GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_model(lr=0.01):\n",
    "    base_model = ResNet50(weights='imagenet') \n",
    "    x = base_model.layers[-2].output\n",
    "    prediction = Dense(5270, activation='softmax')(x)\n",
    "    model_fine = Model(input=base_model.input, output=prediction)\n",
    "    model_fine.load_weights(\"weights/weights.best7.hdf5\")\n",
    "    optimizer = Adam(lr=lr)\n",
    "    model_fine.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model_fine\n",
    "\n",
    "param_grid = dict(lr=[0.00001, 0.000033, 0.0001, 0.00033, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2162/2162 [01:33<00:00, 23.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# The hyper-parameter tunning will be performed on the first 1/20 of the training set\n",
    "X = []\n",
    "Y = []\n",
    "steps_tune = int(steps_train/20)\n",
    "for i in tqdm(range(steps_tune)):\n",
    "    x, y = next(train_gen)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "X = np.vstack(X)\n",
    "Y = np.concatenate(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=4, batch_size=15, verbose=1)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1b  Use the optimal learning rate to fine tune the weights of the entire ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout,GlobalAveragePooling2D\n",
    "\n",
    "\n",
    "\n",
    "base_model = ResNet50(weights='imagenet') \n",
    "\n",
    "x = base_model.layers[-2].output\n",
    "prediction = Dense(5270, activation='softmax')(x)\n",
    "model_fine = Model(input=base_model.input, output=prediction)\n",
    "\n",
    "# Load the weights of the model trained in the previous step\n",
    "model_fine.load_weights(\"weights/weights.best7.hdf5\")\n",
    "model_fine.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Train with a much lower learning rate\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model_fine.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "check_pointer = ModelCheckpoint(filepath='weights/weights.best.fine1.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 4.2222 - acc: 0.2686Epoch 00001: val_loss improved from inf to 3.93237, saving model to weights/weights.best.fine1.hdf5\n",
      "27034/27034 [==============================] - 14901s 551ms/step - loss: 4.2222 - acc: 0.2686 - val_loss: 3.9324 - val_acc: 0.3546\n",
      "Epoch 2/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 3.3939 - acc: 0.3758Epoch 00002: val_loss improved from 3.93237 to 3.72420, saving model to weights/weights.best.fine1.hdf5\n",
      "27034/27034 [==============================] - 14887s 551ms/step - loss: 3.3939 - acc: 0.3758 - val_loss: 3.7242 - val_acc: 0.3855\n",
      "Epoch 3/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 2.9462 - acc: 0.4381Epoch 00003: val_loss improved from 3.72420 to 3.58259, saving model to weights/weights.best.fine1.hdf5\n",
      "27034/27034 [==============================] - 14991s 555ms/step - loss: 2.9461 - acc: 0.4381 - val_loss: 3.5826 - val_acc: 0.4066\n",
      "Epoch 4/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 2.6229 - acc: 0.4849Epoch 00004: val_loss improved from 3.58259 to 3.57294, saving model to weights/weights.best.fine1.hdf5\n",
      "27034/27034 [==============================] - 15035s 556ms/step - loss: 2.6228 - acc: 0.4849 - val_loss: 3.5729 - val_acc: 0.4106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a40029278>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fine.fit_generator(train_gen, steps_per_epoch=steps_train, epochs=4, verbose=1,\n",
    "                             callbacks=[check_pointer], validation_data=valid_gen, validation_steps=steps_valid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fine.save('weights/fullmodel.best.fine1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 2.3608 - acc: 0.5234Epoch 00001: val_loss improved from inf to 3.47892, saving model to weights/weights.best.fine2.hdf5\n",
      "27034/27034 [==============================] - 15044s 556ms/step - loss: 2.3608 - acc: 0.5234 - val_loss: 3.4789 - val_acc: 0.4279\n",
      "Epoch 2/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 2.1388 - acc: 0.5569Epoch 00002: val_loss did not improve\n",
      "27034/27034 [==============================] - 15053s 557ms/step - loss: 2.1388 - acc: 0.5569 - val_loss: 3.4796 - val_acc: 0.4341\n",
      "Epoch 3/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 1.9498 - acc: 0.5871Epoch 00003: val_loss did not improve\n",
      "27034/27034 [==============================] - 15094s 558ms/step - loss: 1.9498 - acc: 0.5871 - val_loss: 3.5375 - val_acc: 0.4352\n",
      "Epoch 4/4\n",
      "27033/27034 [============================>.] - ETA: 0s - loss: 1.7861 - acc: 0.6122Epoch 00004: val_loss did not improve\n",
      "27034/27034 [==============================] - 15109s 559ms/step - loss: 1.7861 - acc: 0.6122 - val_loss: 3.4805 - val_acc: 0.4440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9a43edbd30>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_pointer = ModelCheckpoint(filepath='weights/weights.best.fine2.hdf5', verbose=1, save_best_only=True)\n",
    "model_fine.fit_generator(train_gen, steps_per_epoch=steps_train, epochs=4, verbose=1,\n",
    "                             callbacks=[check_pointer], validation_data=valid_gen, validation_steps=steps_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Test the performance of the fine-tuned model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model_fine = load_model('weights/fullmodel.best.fine3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = test_set[:,0], test_set[:,1]\n",
    "labels= labels.astype('int')\n",
    "\n",
    "def predict(paths, batch_size=256):\n",
    "    n_batches = int(np.ceil(len(paths)/batch_size))\n",
    "    predictions = []\n",
    "    for n in tqdm(range(n_batches)):\n",
    "        if n != n_batches-1:\n",
    "            paths_n = paths[n*batch_size:(n+1)*batch_size]\n",
    "        else:\n",
    "            paths_n = paths[n*batch_size:]\n",
    "        X = paths_to_tensor(paths_n)\n",
    "        predictions += list(np.argmax(model_fine.predict(preprocess_input(X)), axis=1))\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [14:02<00:00,  6.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.449371137882\n"
     ]
    }
   ],
   "source": [
    "predictions =predict(features, batch_size=1000)\n",
    "print('accuracy: ', sum(predictions == labels)/len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_fine.save('weights/fullmodel.best.fine3.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate the bottleneck features using the fine tuned model of the last step\n",
    "### 6.1 Set up the model (model_bnf) to output the predicted category and the bottleneck features before the last fully-connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jin/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, Model\n",
    "\n",
    "model = load_model('weights/fullmodel.best.fine3.hdf5')\n",
    "output = [model.layers[-2].output, model.output]\n",
    "model_bnf = Model(input=model.input, output=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Calculate the bottleneck features for all the images of the training set and save them in a sorted state according to their categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1082/1082 [2:09:04<00:00,  7.16s/it] \n"
     ]
    }
   ],
   "source": [
    "# The bottleneck features are put into a dictionary, where the keys are the indices of categories,\n",
    "# and the corresponding values are lists of bottleneck features from images with the same label.\n",
    "train_sorted = {}  \n",
    "predictions = [] # record the prediction of the model for each training image\n",
    "for n in tqdm(range(steps_train)):\n",
    "    features, labels = next(train_gen)\n",
    "    bnfeatures = model_bnf.predict(features)\n",
    "    labels_n = [list(i).index(1) for i in labels]\n",
    "    predictions += labels_n\n",
    "    for bnf, label in zip(bnfeatures, labels_n):\n",
    "        keys = train_sorted.keys()\n",
    "        if label not in keys:\n",
    "            train_sorted[label] = []\n",
    "        train_sorted[label].append(bnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load, dump, HIGHEST_PROTOCOL\n",
    "\n",
    "# Save the calculated bottleneck features and the predicted categories for the training set\n",
    "with open('bnfeature/train_fine3.pickle', 'wb') as f:\n",
    "    dump(train_sorted, f, HIGHEST_PROTOCOL)\n",
    "with open('prediction/fine3_train.pickle', 'wb') as f:\n",
    "    dump(predictions, f, HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Calculate the bottleneck features for all the images of the valid set and save them in a sorted state according to their categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_sorted = {}  \n",
    "predictions = [] \n",
    "for n in tqdm(range(steps_valid)):\n",
    "    features, labels = next(valid_gen)\n",
    "    bnfeatures = model_bnf.predict(features)\n",
    "    labels_n = [list(i).index(1) for i in labels]\n",
    "    predictions += labels_n\n",
    "    for bnf, label in zip(bnfeatures, labels_n):\n",
    "        keys = valid_sorted.keys()\n",
    "        if label not in keys:\n",
    "            valid_sorted[label] = []\n",
    "        valid_sorted[label].append(bnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pickle import load, dump, HIGHEST_PROTOCOL\n",
    "with open('bnfeature/valid3_fine.pickle', 'wb') as f:\n",
    "    dump(valid_sorted, f, HIGHEST_PROTOCOL)\n",
    "with open('prediction/fine3_valid.pickle', 'wb') as f:\n",
    "    dump(predictions, f, HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
